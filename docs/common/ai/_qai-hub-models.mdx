[**Qualcomm® AI Hub Models**](https://github.com/quic/ai-hub-models)（QAI-Hub-Models）
基于 [QAI-Hub](https://app.aihub.qualcomm.com/docs/index.html) 提供的云服务，支持以命令行方式将[模型列表](#模型列表)中的模型在云设备上进行在线**量化、编译、推理、分析和下载**。

## 使用方法

### 安装 qai_hub_models

<NewCodeBlock tip="Device" type="device">

```bash
pip3 install qai_hub_models
```

</NewCodeBlock>

### 配置 API Token

:::tip
请先在 [Qualcomm® AI Hub](https://aihub.qualcomm.com/) 上进行账户注册并登陆，获取用户 **`API Token`**
:::

<NewCodeBlock tip="Device" type="device">

```bash
qai-hub configure --api_token API_TOKEN
```

</NewCodeBlock>

## 使用示例

### QAI HUB MODELS 模型编译示例

这里以编译 [RealESRGAN_x4plus](https://github.com/xinntao/Real-ESRGAN) 为可以在 QCS6490 SoC 上使用 NPU 进行推理的输入大小为 128x128 w8a8 量化 的 Context-Binary 模型格式为例子,
简单介绍使用 Qualcomm® AI Hub Models 进行模型编译的使用方法。

<NewCodeBlock tip="Device" type="device">

```bash
python3 -m qai_hub_models.models.real_esrgan_x4plus.export --chipset "qualcomm-qcs6490-proxy" --target-runtime qnn_context_binary  --height 128 --width 128 --quantize w8a8 --num-calibration-samples 10
```

</NewCodeBlock>

`--chipset` 指定目标运行的芯片

`--target-runtime` 指定目标运行时

`--height` 目标模型输入高度

`--width` 目标模型输入宽度

`--quantize` 指定量化方式

`--num-calibration-samples` 指定量化校准集图片数量

:::tip
qai_hub_models.models.real_esrgan_x4plus.export 的详细使用方法请使用 **`--hlep`** 查看

模型编译的所有信息和日志可以在 Qualcomm® AI Hub 里的 `JOBS` 进行查看
:::

```bash
(.venv) (base) radxa@vms-max:/mnt/sda1/qualcomm/qai-hub/ai_hub_model$ python3 -m qai_hub_models.models.real_esrgan_x4plus.export --chipset "qualcomm-qcs6490-proxy" --target-runtime qnn_context_binary  --height 128 --width 128 --quantize w8a8 --num-calibration-samples 10
Quantizing model real_esrgan_x4plus.
Uploading tmplaenxfnu.pt
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 64.8M/64.8M [00:06<00:00, 11.1MB/s]
Scheduled compile job (jgon7zqkp) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jgon7zqkp/

Loading 10 calibration samples.
Waiting for compile job (jgon7zqkp) completion. Type Ctrl+C to stop waiting at any time.
    ✅ SUCCESS
Uploading dataset: 700kB [00:01, 522kB/s]
Scheduled quantize job (jpew0o3vp) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jpew0o3vp/

Waiting for quantize job (jpew0o3vp) completion. Type Ctrl+C to stop waiting at any time.
    ✅ SUCCESS
Optimizing model real_esrgan_x4plus to run on-device
Scheduled compile job (jgdqynlz5) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jgdqynlz5/

Profiling model real_esrgan_x4plus on a hosted device.
Waiting for compile job (jgdqynlz5) completion. Type Ctrl+C to stop waiting at any time.
    ✅ SUCCESS
Scheduled profile job (jp4d6n01p) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jp4d6n01p/

Running inference for real_esrgan_x4plus on a hosted device with example inputs.
Downloading data at https://qaihub-public-assets.s3.us-west-2.amazonaws.com/qai-hub-models/models/super_resolution/v2/super_resolution_input.jpg to /home/zifeng/.qaihm/models/super_resolution/v2/super_resolution_input.jpg
100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16.5k/16.5k [00:00<00:00, 92.2MB/s]
Done
Uploading dataset: 104kB [00:01, 100kB/s]
Scheduled inference job (jpx6892lp) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jpx6892lp/

real_esrgan_x4plus.bin: 100%|██████████████████████████████████████████████████████████████████████████| 21.5M/21.5M [00:02<00:00, 7.97MB/s]
Downloaded model to /mnt/sda1/qualcomm/qai-hub/ai_hub_model/build/real_esrgan_x4plus/real_esrgan_x4plus.bin
Waiting for profile job (jp4d6n01p) completion. Type Ctrl+C to stop waiting at any time.
    ✅ SUCCESS

------------------------------------------------------------
Performance results on-device for Real_Esrgan_X4Plus.
------------------------------------------------------------
Device                          : QCS6490 (Proxy) (ANDROID 12)
Runtime                         : QNN_CONTEXT_BINARY
Estimated inference time (ms)   : 171.8
Estimated peak memory usage (MB): [0, 13]
Total # Ops                     : 1027
Compute Unit(s)                 : npu (1027 ops) gpu (0 ops) cpu (0 ops)
------------------------------------------------------------
More details: https://app.aihub.qualcomm.com/jobs/jp4d6n01p/

tmpz9r34tur.h5: 100%|███████████████████████████████████████████████████████████████████████████████████| 1.05M/1.05M [00:03<00:00, 357kB/s]

Comparing on-device vs. local-cpu inference for Real_Esrgan_X4Plus.
+----------------+------------------+--------+
| output_name    | shape            |   psnr |
+================+==================+========+
| upscaled_image | (1, 512, 512, 3) |  24.49 |
+----------------+------------------+--------+

- psnr: Peak Signal-to-Noise Ratio (PSNR). >30 dB is typically considered good.

More details: https://app.aihub.qualcomm.com/jobs/jpx6892lp/

Run compiled model on a hosted device on sample data using:
python /mnt/sda1/qualcomm/qai-hub/.venv/lib/python3.10/site-packages/qai_hub_models/models/real_esrgan_x4plus/demo.py --eval-mode on-device --hub-model-id mm63gld2m --chipset qualcomm-qcs6490-proxy
```

### QAI HUB MODELS 模型推理 Demo

根据用户[模型编译示例](#qai-hub-models-模型编译示例)中最后的打引提示，可以在云端设备上推理编译后模型并查看推理结果

:::tip
请修改 `hub-model-id` 参数为模型编译结果最后打印的 `hub-model-id`
:::

<div style={{ textAlign: "center" }}>
  <img src="/img/dragon/q6a/ai-hub-model-example_2.webp" style={{ width: "100%" }} />
  hub-model-id 具体参数位置
</div>
<NewCodeBlock tip="Device" type="device">

```bash
python3 -m qai_hub_models.models.real_esrgan_x4plus.demo --eval-mode on-device --hub-model-id mm63gld2m --chipset qualcomm-qcs6490-proxy
```

</NewCodeBlock>

```bash
(.venv) (gen_py3.10) radxa@vms-max:~/Job/git_clone/ai-hub-models$ python3 -m qai_hub_models.models.real_esrgan_x4plus.demo --eval-mode on-device --hub-model-id mm63gld2m --chipset qualcomm-qcs6490-proxy
/mnt/sda1/git_clone/ai-hub-models/.venv/lib/python3.10/site-packages/qai_hub_models/utils/onnx_torch_wrapper.py:22: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Model Loaded
Uploading dataset: 104kB [00:02, 52.5kB/s]
Scheduled inference job (jgj29j8e5) successfully. To see the status and results:
    https://app.aihub.qualcomm.com/jobs/jgj29j8e5/

Waiting for inference job (jgj29j8e5) completion. Type Ctrl+C to stop waiting at any time.
    ✅ SUCCESS
tmpe9b4q_c2.h5: 100%|██████████████████████████████████████████████████████████████████████████████████| 1.03M/1.03M [00:00<00:00, 2.04MB/s]
Displaying original image
Displaying upscaled image
```

<div style={{ textAlign: "center" }}>
  <img
    src="/img/dragon/q6a/ai-hub-model-example.webp"
    style={{ width: "90%" }}
  />
  左边为结果图，右边为输入图
</div>

## 模型列表

### Computer Vision

| Model                                                                                    | README                                                                                                                                             |
| ---------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Image Classification**                                                                 |                                                                                                                                                    |
| [Beit](https://aihub.qualcomm.com/models/beit)                                           | [qai_hub_models.models.beit](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/beit)                                           |
| [ConvNext-Base](https://aihub.qualcomm.com/models/convnext_base)                         | [qai_hub_models.models.convnext_base](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/convnext_base)                         |
| [ConvNext-Tiny](https://aihub.qualcomm.com/models/convnext_tiny)                         | [qai_hub_models.models.convnext_tiny](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/convnext_tiny)                         |
| [DLA-102-X](https://aihub.qualcomm.com/models/dla102x)                                   | [qai_hub_models.models.dla102x](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/dla102x)                                     |
| [DenseNet-121](https://aihub.qualcomm.com/models/densenet121)                            | [qai_hub_models.models.densenet121](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/densenet121)                             |
| [EfficientFormer](https://aihub.qualcomm.com/models/efficientformer)                     | [qai_hub_models.models.efficientformer](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientformer)                     |
| [EfficientNet-B0](https://aihub.qualcomm.com/models/efficientnet_b0)                     | [qai_hub_models.models.efficientnet_b0](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientnet_b0)                     |
| [EfficientNet-B4](https://aihub.qualcomm.com/models/efficientnet_b4)                     | [qai_hub_models.models.efficientnet_b4](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientnet_b4)                     |
| [EfficientNet-V2-s](https://aihub.qualcomm.com/models/efficientnet_v2_s)                 | [qai_hub_models.models.efficientnet_v2_s](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientnet_v2_s)                 |
| [EfficientViT-b2-cls](https://aihub.qualcomm.com/models/efficientvit_b2_cls)             | [qai_hub_models.models.efficientvit_b2_cls](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientvit_b2_cls)             |
| [EfficientViT-l2-cls](https://aihub.qualcomm.com/models/efficientvit_l2_cls)             | [qai_hub_models.models.efficientvit_l2_cls](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientvit_l2_cls)             |
| [GoogLeNet](https://aihub.qualcomm.com/models/googlenet)                                 | [qai_hub_models.models.googlenet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/googlenet)                                 |
| [Inception-v3](https://aihub.qualcomm.com/models/inception_v3)                           | [qai_hub_models.models.inception_v3](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/inception_v3)                           |
| [LeViT](https://aihub.qualcomm.com/models/levit)                                         | [qai_hub_models.models.levit](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/levit)                                         |
| [MNASNet05](https://aihub.qualcomm.com/models/mnasnet05)                                 | [qai_hub_models.models.mnasnet05](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mnasnet05)                                 |
| [Mobile-VIT](https://aihub.qualcomm.com/models/mobile_vit)                               | [qai_hub_models.models.mobile_vit](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mobile_vit)                               |
| [MobileNet-v2](https://aihub.qualcomm.com/models/mobilenet_v2)                           | [qai_hub_models.models.mobilenet_v2](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mobilenet_v2)                           |
| [MobileNet-v3-Large](https://aihub.qualcomm.com/models/mobilenet_v3_large)               | [qai_hub_models.models.mobilenet_v3_large](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mobilenet_v3_large)               |
| [MobileNet-v3-Small](https://aihub.qualcomm.com/models/mobilenet_v3_small)               | [qai_hub_models.models.mobilenet_v3_small](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mobilenet_v3_small)               |
| [NASNet](https://aihub.qualcomm.com/models/nasnet)                                       | [qai_hub_models.models.nasnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/nasnet)                                       |
| [RegNet](https://aihub.qualcomm.com/models/regnet)                                       | [qai_hub_models.models.regnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/regnet)                                       |
| [ResNeXt101](https://aihub.qualcomm.com/models/resnext101)                               | [qai_hub_models.models.resnext101](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnext101)                               |
| [ResNeXt50](https://aihub.qualcomm.com/models/resnext50)                                 | [qai_hub_models.models.resnext50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnext50)                                 |
| [ResNet101](https://aihub.qualcomm.com/models/resnet101)                                 | [qai_hub_models.models.resnet101](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet101)                                 |
| [ResNet18](https://aihub.qualcomm.com/models/resnet18)                                   | [qai_hub_models.models.resnet18](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet18)                                   |
| [ResNet50](https://aihub.qualcomm.com/models/resnet50)                                   | [qai_hub_models.models.resnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet50)                                   |
| [Sequencer2D](https://aihub.qualcomm.com/models/sequencer2d)                             | [qai_hub_models.models.sequencer2d](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/sequencer2d)                             |
| [Shufflenet-v2](https://aihub.qualcomm.com/models/shufflenet_v2)                         | [qai_hub_models.models.shufflenet_v2](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/shufflenet_v2)                         |
| [SqueezeNet-1.1](https://aihub.qualcomm.com/models/squeezenet1_1)                        | [qai_hub_models.models.squeezenet1_1](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/squeezenet1_1)                         |
| [Swin-Base](https://aihub.qualcomm.com/models/swin_base)                                 | [qai_hub_models.models.swin_base](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/swin_base)                                 |
| [Swin-Small](https://aihub.qualcomm.com/models/swin_small)                               | [qai_hub_models.models.swin_small](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/swin_small)                               |
| [Swin-Tiny](https://aihub.qualcomm.com/models/swin_tiny)                                 | [qai_hub_models.models.swin_tiny](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/swin_tiny)                                 |
| [VIT](https://aihub.qualcomm.com/models/vit)                                             | [qai_hub_models.models.vit](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/vit)                                             |
| [WideResNet50](https://aihub.qualcomm.com/models/wideresnet50)                           | [qai_hub_models.models.wideresnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/wideresnet50)                           |
| **Image Editing**                                                                        |                                                                                                                                                    |
| [AOT-GAN](https://aihub.qualcomm.com/models/aotgan)                                      | [qai_hub_models.models.aotgan](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/aotgan)                                       |
| [LaMa-Dilated](https://aihub.qualcomm.com/models/lama_dilated)                           | [qai_hub_models.models.lama_dilated](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/lama_dilated)                           |
| **Image Generation**                                                                     |                                                                                                                                                    |
| [Simple-Bev](https://aihub.qualcomm.com/models/simple_bev_cam)                           | [qai_hub_models.models.simple_bev_cam](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/simple_bev_cam)                       |
| **Super Resolution**                                                                     |                                                                                                                                                    |
| [ESRGAN](https://aihub.qualcomm.com/models/esrgan)                                       | [qai_hub_models.models.esrgan](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/esrgan)                                       |
| [QuickSRNetLarge](https://aihub.qualcomm.com/models/quicksrnetlarge)                     | [qai_hub_models.models.quicksrnetlarge](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/quicksrnetlarge)                     |
| [QuickSRNetMedium](https://aihub.qualcomm.com/models/quicksrnetmedium)                   | [qai_hub_models.models.quicksrnetmedium](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/quicksrnetmedium)                   |
| [QuickSRNetSmall](https://aihub.qualcomm.com/models/quicksrnetsmall)                     | [qai_hub_models.models.quicksrnetsmall](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/quicksrnetsmall)                     |
| [Real-ESRGAN-General-x4v3](https://aihub.qualcomm.com/models/real_esrgan_general_x4v3)   | [qai_hub_models.models.real_esrgan_general_x4v3](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/real_esrgan_general_x4v3)   |
| [Real-ESRGAN-x4plus](https://aihub.qualcomm.com/models/real_esrgan_x4plus)               | [qai_hub_models.models.real_esrgan_x4plus](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/real_esrgan_x4plus)               |
| [SESR-M5](https://aihub.qualcomm.com/models/sesr_m5)                                     | [qai_hub_models.models.sesr_m5](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/sesr_m5)                                     |
| [XLSR](https://aihub.qualcomm.com/models/xlsr)                                           | [qai_hub_models.models.xlsr](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/xlsr)                                           |
| **Semantic Segmentation**                                                                |                                                                                                                                                    |
| [BGNet](https://aihub.qualcomm.com/models/bgnet)                                         | [qai_hub_models.models.bgnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/bgnet)                                         |
| [BiseNet](https://aihub.qualcomm.com/models/bisenet)                                     | [qai_hub_models.models.bisenet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/bisenet)                                     |
| [DDRNet23-Slim](https://aihub.qualcomm.com/models/ddrnet23_slim)                         | [qai_hub_models.models.ddrnet23_slim](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ddrnet23_slim)                         |
| [DeepLabV3-Plus-MobileNet](https://aihub.qualcomm.com/models/deeplabv3_plus_mobilenet)   | [qai_hub_models.models.deeplabv3_plus_mobilenet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/deeplabv3_plus_mobilenet)   |
| [DeepLabV3-ResNet50](https://aihub.qualcomm.com/models/deeplabv3_resnet50)               | [qai_hub_models.models.deeplabv3_resnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/deeplabv3_resnet50)               |
| [DeepLabXception](https://aihub.qualcomm.com/models/deeplab_xception)                    | [qai_hub_models.models.deeplab_xception](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/deeplab_xception)                   |
| [EfficientViT-l2-seg](https://aihub.qualcomm.com/models/efficientvit_l2_seg)             | [qai_hub_models.models.efficientvit_l2_seg](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/efficientvit_l2_seg)             |
| [FCN-ResNet50](https://aihub.qualcomm.com/models/fcn_resnet50)                           | [qai_hub_models.models.fcn_resnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/fcn_resnet50)                           |
| [FFNet-122NS-LowRes](https://aihub.qualcomm.com/models/ffnet_122ns_lowres)               | [qai_hub_models.models.ffnet_122ns_lowres](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ffnet_122ns_lowres)               |
| [FFNet-40S](https://aihub.qualcomm.com/models/ffnet_40s)                                 | [qai_hub_models.models.ffnet_40s](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ffnet_40s)                                 |
| [FFNet-54S](https://aihub.qualcomm.com/models/ffnet_54s)                                 | [qai_hub_models.models.ffnet_54s](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ffnet_54s)                                 |
| [FFNet-78S](https://aihub.qualcomm.com/models/ffnet_78s)                                 | [qai_hub_models.models.ffnet_78s](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ffnet_78s)                                 |
| [FFNet-78S-LowRes](https://aihub.qualcomm.com/models/ffnet_78s_lowres)                   | [qai_hub_models.models.ffnet_78s_lowres](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ffnet_78s_lowres)                   |
| [FastSam-S](https://aihub.qualcomm.com/models/fastsam_s)                                 | [qai_hub_models.models.fastsam_s](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/fastsam_s)                                 |
| [FastSam-X](https://aihub.qualcomm.com/models/fastsam_x)                                 | [qai_hub_models.models.fastsam_x](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/fastsam_x)                                 |
| [HRNet-W48-OCR](https://aihub.qualcomm.com/models/hrnet_w48_ocr)                         | [qai_hub_models.models.hrnet_w48_ocr](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/hrnet_w48_ocr)                         |
| [Mask2Former](https://aihub.qualcomm.com/models/mask2former)                             | [qai_hub_models.models.mask2former](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mask2former)                             |
| [MediaPipe-Selfie-Segmentation](https://aihub.qualcomm.com/models/mediapipe_selfie)      | [qai_hub_models.models.mediapipe_selfie](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mediapipe_selfie)                   |
| [MobileSam](https://aihub.qualcomm.com/models/mobilesam)                                 | [qai_hub_models.models.mobilesam](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mobilesam)                                 |
| [PidNet](https://aihub.qualcomm.com/models/pidnet)                                       | [qai_hub_models.models.pidnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/pidnet)                                       |
| [SINet](https://aihub.qualcomm.com/models/sinet)                                         | [qai_hub_models.models.sinet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/sinet)                                         |
| [SalsaNext](https://aihub.qualcomm.com/models/salsanext)                                 | [qai_hub_models.models.salsanext](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/salsanext)                                 |
| [Segformer-Base](https://aihub.qualcomm.com/models/segformer_base)                       | [qai_hub_models.models.segformer_base](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/segformer_base)                       |
| [Segment-Anything-Model-2](https://aihub.qualcomm.com/models/sam2)                       | [qai_hub_models.models.sam2](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/sam2)                                           |
| [Unet-Segmentation](https://aihub.qualcomm.com/models/unet_segmentation)                 | [qai_hub_models.models.unet_segmentation](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/unet_segmentation)                 |
| [YOLOv11-Segmentation](https://aihub.qualcomm.com/models/yolov11_seg)                    | [qai_hub_models.models.yolov11_seg](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov11_seg)                             |
| [YOLOv8-Segmentation](https://aihub.qualcomm.com/models/yolov8_seg)                      | [qai_hub_models.models.yolov8_seg](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov8_seg)                               |
| **Video Classification**                                                                 |                                                                                                                                                    |
| [ResNet-2Plus1D](https://aihub.qualcomm.com/models/resnet_2plus1d)                       | [qai_hub_models.models.resnet_2plus1d](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet_2plus1d)                       |
| [ResNet-3D](https://aihub.qualcomm.com/models/resnet_3d)                                 | [qai_hub_models.models.resnet_3d](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet_3d)                                 |
| [ResNet-Mixed-Convolution](https://aihub.qualcomm.com/models/resnet_mixed)               | [qai_hub_models.models.resnet_mixed](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/resnet_mixed)                           |
| [Video-MAE](https://aihub.qualcomm.com/models/video_mae)                                 | [qai_hub_models.models.video_mae](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/video_mae)                                 |
| **Video Generation**                                                                     |                                                                                                                                                    |
| [First-Order-Motion-Model](https://aihub.qualcomm.com/models/fomm)                       | [qai_hub_models.models.fomm](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/fomm)                                           |
| **Object Detection**                                                                     |                                                                                                                                                    |
| [3D-Deep-BOX](https://aihub.qualcomm.com/models/deepbox)                                 | [qai_hub_models.models.deepbox](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/deepbox)                                     |
| [Conditional-DETR-ResNet50](https://aihub.qualcomm.com/models/conditional_detr_resnet50) | [qai_hub_models.models.conditional_detr_resnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/conditional_detr_resnet50) |
| [DETR-ResNet101](https://aihub.qualcomm.com/models/detr_resnet101)                       | [qai_hub_models.models.detr_resnet101](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/detr_resnet101)                       |
| [DETR-ResNet101-DC5](https://aihub.qualcomm.com/models/detr_resnet101_dc5)               | [qai_hub_models.models.detr_resnet101_dc5](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/detr_resnet101_dc5)               |
| [DETR-ResNet50](https://aihub.qualcomm.com/models/detr_resnet50)                         | [qai_hub_models.models.detr_resnet50](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/detr_resnet50)                         |
| [DETR-ResNet50-DC5](https://aihub.qualcomm.com/models/detr_resnet50_dc5)                 | [qai_hub_models.models.detr_resnet50_dc5](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/detr_resnet50_dc5)                 |
| [Facial-Attribute-Detection](https://aihub.qualcomm.com/models/face_attrib_net)          | [qai_hub_models.models.face_attrib_net](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/face_attrib_net)                     |
| [Lightweight-Face-Detection](https://aihub.qualcomm.com/models/face_det_lite)            | [qai_hub_models.models.face_det_lite](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/face_det_lite)                         |
| [MediaPipe-Face-Detection](https://aihub.qualcomm.com/models/mediapipe_face)             | [qai_hub_models.models.mediapipe_face](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mediapipe_face)                       |
| [MediaPipe-Hand-Detection](https://aihub.qualcomm.com/models/mediapipe_hand)             | [qai_hub_models.models.mediapipe_hand](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mediapipe_hand)                       |
| [PPE-Detection](https://aihub.qualcomm.com/models/gear_guard_net)                        | [qai_hub_models.models.gear_guard_net](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/gear_guard_net)                       |
| [Person-Foot-Detection](https://aihub.qualcomm.com/models/foot_track_net)                | [qai_hub_models.models.foot_track_net](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/foot_track_net)                       |
| [RF-DETR](https://aihub.qualcomm.com/models/rf_detr)                                     | [qai_hub_models.models.rf_detr](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/rf_detr)                                     |
| [RTMDet](https://aihub.qualcomm.com/models/rtmdet)                                       | [qai_hub_models.models.rtmdet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/rtmdet)                                       |
| [YOLOv10-Detection](https://aihub.qualcomm.com/models/yolov10_det)                       | [qai_hub_models.models.yolov10_det](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov10_det)                             |
| [YOLOv11-Detection](https://aihub.qualcomm.com/models/yolov11_det)                       | [qai_hub_models.models.yolov11_det](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov11_det)                             |
| [YOLOv8-Detection](https://aihub.qualcomm.com/models/yolov8_det)                         | [qai_hub_models.models.yolov8_det](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov8_det)                               |
| [Yolo-X](https://aihub.qualcomm.com/models/yolox)                                        | [qai_hub_models.models.yolox](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolox)                                         |
| [Yolo-v3](https://aihub.qualcomm.com/models/yolov3)                                      | [qai_hub_models.models.yolov3](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov3)                                       |
| [Yolo-v5](https://aihub.qualcomm.com/models/yolov5)                                      | [qai_hub_models.models.yolov5](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov5)                                       |
| [Yolo-v6](https://aihub.qualcomm.com/models/yolov6)                                      | [qai_hub_models.models.yolov6](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov6)                                       |
| [Yolo-v7](https://aihub.qualcomm.com/models/yolov7)                                      | [qai_hub_models.models.yolov7](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yolov7)                                       |
| **Pose Estimation**                                                                      |                                                                                                                                                    |
| [Facial-Landmark-Detection](https://aihub.qualcomm.com/models/facemap_3dmm)              | [qai_hub_models.models.facemap_3dmm](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/facemap_3dmm)                           |
| [HRNetPose](https://aihub.qualcomm.com/models/hrnet_pose)                                | [qai_hub_models.models.hrnet_pose](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/hrnet_pose)                               |
| [LiteHRNet](https://aihub.qualcomm.com/models/litehrnet)                                 | [qai_hub_models.models.litehrnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/litehrnet)                                 |
| [MediaPipe-Pose-Estimation](https://aihub.qualcomm.com/models/mediapipe_pose)            | [qai_hub_models.models.mediapipe_pose](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mediapipe_pose)                       |
| [Movenet](https://aihub.qualcomm.com/models/movenet)                                     | [qai_hub_models.models.movenet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/movenet)                                     |
| [Posenet-Mobilenet](https://aihub.qualcomm.com/models/posenet_mobilenet)                 | [qai_hub_models.models.posenet_mobilenet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/posenet_mobilenet)                 |
| [RTMPose-Body2d](https://aihub.qualcomm.com/models/rtmpose_body2d)                       | [qai_hub_models.models.rtmpose_body2d](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/rtmpose_body2d)                       |
| **Depth Estimation**                                                                     |                                                                                                                                                    |
| [Depth-Anything](https://aihub.qualcomm.com/models/depth_anything)                       | [qai_hub_models.models.depth_anything](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/depth_anything)                       |
| [Depth-Anything-V2](https://aihub.qualcomm.com/models/depth_anything_v2)                 | [qai_hub_models.models.depth_anything_v2](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/depth_anything_v2)                 |
| [Midas-V2](https://aihub.qualcomm.com/models/midas)                                      | [qai_hub_models.models.midas](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/midas)                                         |

### Multimodal

| Model                                                                  | README                                                                                                                           |
| ---------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| [EasyOCR](https://aihub.qualcomm.com/models/easyocr)                   | [qai_hub_models.models.easyocr](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/easyocr)                   |
| [Nomic-Embed-Text](https://aihub.qualcomm.com/models/nomic_embed_text) | [qai_hub_models.models.nomic_embed_text](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/nomic_embed_text) |
| [OpenAI-Clip](https://aihub.qualcomm.com/models/openai_clip)           | [qai_hub_models.models.openai_clip](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/openai_clip)           |
| [TrOCR](https://aihub.qualcomm.com/models/trocr)                       | [qai_hub_models.models.trocr](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/trocr)                       |

### Audio

| Model                                                                                        | README                                                                                                                                                 |
| -------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **Speech Recognition**                                                                       |                                                                                                                                                        |
| [HuggingFace-WavLM-Base-Plus](https://aihub.qualcomm.com/models/huggingface_wavlm_base_plus) | [qai_hub_models.models.huggingface_wavlm_base_plus](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/huggingface_wavlm_base_plus) |
| [Whisper-Base](https://aihub.qualcomm.com/models/whisper_base)                               | [qai_hub_models.models.whisper_base](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/whisper_base)                               |
| [Whisper-Large-V3-Turbo](https://aihub.qualcomm.com/models/whisper_large_v3_turbo)           | [qai_hub_models.models.whisper_large_v3_turbo](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/whisper_large_v3_turbo)           |
| [Whisper-Small](https://aihub.qualcomm.com/models/whisper_small)                             | [qai_hub_models.models.whisper_small](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/whisper_small)                             |
| [Whisper-Tiny](https://aihub.qualcomm.com/models/whisper_tiny)                               | [qai_hub_models.models.whisper_tiny](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/whisper_tiny)                               |
| **Audio Classification**                                                                     |                                                                                                                                                        |
| [YamNet](https://aihub.qualcomm.com/models/yamnet)                                           | [qai_hub_models.models.yamnet](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/yamnet)                                           |

### Generative AI

| Model                                                                                          | README                                                                                                                                                   |
| ---------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Image Generation**                                                                           |                                                                                                                                                          |
| [ControlNet-Canny](https://aihub.qualcomm.com/models/controlnet_canny)                         | [qai_hub_models.models.controlnet_canny](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/controlnet_canny)                         |
| [Stable-Diffusion-v1.5](https://aihub.qualcomm.com/models/stable_diffusion_v1_5)               | [qai_hub_models.models.stable_diffusion_v1_5](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/stable_diffusion_v1_5)               |
| [Stable-Diffusion-v2.1](https://aihub.qualcomm.com/models/stable_diffusion_v2_1)               | [qai_hub_models.models.stable_diffusion_v2_1](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/stable_diffusion_v2_1)               |
| **Text Generation**                                                                            |                                                                                                                                                          |
| [ALLaM-7B](https://aihub.qualcomm.com/models/allam_7b)                                         | [qai_hub_models.models.allam_7b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/allam_7b)                                         |
| [Baichuan2-7B](https://aihub.qualcomm.com/models/baichuan2_7b)                                 | [qai_hub_models.models.baichuan2_7b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/baichuan2_7b)                                 |
| [Falcon3-7B-Instruct](https://aihub.qualcomm.com/models/falcon_v3_7b_instruct)                 | [qai_hub_models.models.falcon_v3_7b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/falcon_v3_7b_instruct)               |
| [IBM-Granite-v3.1-8B-Instruct](https://aihub.qualcomm.com/models/ibm_granite_v3_1_8b_instruct) | [qai_hub_models.models.ibm_granite_v3_1_8b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ibm_granite_v3_1_8b_instruct) |
| [IndusQ-1.1B](https://aihub.qualcomm.com/models/indus_1b)                                      | [qai_hub_models.models.indus_1b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/indus_1b)                                         |
| [JAIS-6p7b-Chat](https://aihub.qualcomm.com/models/jais_6p7b_chat)                             | [qai_hub_models.models.jais_6p7b_chat](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/jais_6p7b_chat)                             |
| [Llama-SEA-LION-v3.5-8B-R](https://aihub.qualcomm.com/models/llama_v3_1_sea_lion_3_5_8b_r)     | [qai_hub_models.models.llama_v3_1_sea_lion_3_5_8b_r](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_1_sea_lion_3_5_8b_r) |
| [Llama-v2-7B-Chat](https://aihub.qualcomm.com/models/llama_v2_7b_chat)                         | [qai_hub_models.models.llama_v2_7b_chat](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v2_7b_chat)                         |
| [Llama-v3-8B-Instruct](https://aihub.qualcomm.com/models/llama_v3_8b_instruct)                 | [qai_hub_models.models.llama_v3_8b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_8b_instruct)                 |
| [Llama-v3.1-8B-Instruct](https://aihub.qualcomm.com/models/llama_v3_1_8b_instruct)             | [qai_hub_models.models.llama_v3_1_8b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_1_8b_instruct)             |
| [Llama-v3.2-1B-Instruct](https://aihub.qualcomm.com/models/llama_v3_2_1b_instruct)             | [qai_hub_models.models.llama_v3_2_1b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_2_1b_instruct)             |
| [Llama-v3.2-3B-Instruct](https://aihub.qualcomm.com/models/llama_v3_2_3b_instruct)             | [qai_hub_models.models.llama_v3_2_3b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_2_3b_instruct)             |
| [Llama3-TAIDE-LX-8B-Chat-Alpha1](https://aihub.qualcomm.com/models/llama_v3_taide_8b_chat)     | [qai_hub_models.models.llama_v3_taide_8b_chat](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/llama_v3_taide_8b_chat)             |
| [Ministral-3B](https://aihub.qualcomm.com/models/ministral_3b)                                 | [qai_hub_models.models.ministral_3b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/ministral_3b)                                 |
| [Mistral-3B](https://aihub.qualcomm.com/models/mistral_3b)                                     | [qai_hub_models.models.mistral_3b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mistral_3b)                                     |
| [Mistral-7B-Instruct-v0.3](https://aihub.qualcomm.com/models/mistral_7b_instruct_v0_3)         | [qai_hub_models.models.mistral_7b_instruct_v0_3](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/mistral_7b_instruct_v0_3)         |
| [PLaMo-1B](https://aihub.qualcomm.com/models/plamo_1b)                                         | [qai_hub_models.models.plamo_1b](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/plamo_1b)                                         |
| [Phi-3.5-Mini-Instruct](https://aihub.qualcomm.com/models/phi_3_5_mini_instruct)               | [qai_hub_models.models.phi_3_5_mini_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/phi_3_5_mini_instruct)               |
| [Qwen2-7B-Instruct](https://aihub.qualcomm.com/models/qwen2_7b_instruct)                       | [qai_hub_models.models.qwen2_7b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/qwen2_7b_instruct)                       |
| [Qwen2.5-7B-Instruct](https://aihub.qualcomm.com/models/qwen2_5_7b_instruct)                   | [qai_hub_models.models.qwen2_5_7b_instruct](https://github.com/quic/ai-hub-models/tree/main/qai_hub_models/models/qwen2_5_7b_instruct)                   |
