:::tip
This document demonstrates how to run on-board inference of the ResNet50 object classification model on Allwinner T527/A733 series chips.
:::

This example uses a pre-trained ONNX format model from [resnet50-v2-7.onnx](https://github.com/onnx/models/blob/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx) as an example to demonstrate the complete process from model conversion to on-board inference.

Deploying ResNet50 on the board requires two steps:

- On the PC side, use [ACUITY Toolkit](./cubie_acuity_sdk#acuity-toolkit) to convert models from different frameworks to NBG format
- On the board side, use the awnn API for model inference

## Download ai-sdk Example Repository

<NewCodeBlock tip="X86 PC / Device" type="PC">

```bash
git clone https://github.com/ZIFENG278/ai-sdk.git
```

</NewCodeBlock>

## PC-Side Model Conversion

:::tip
Radxa provides a pre-converted `resnet50.nb` model. Users can directly refer to [**On-board ResNet50 Inference** ](#board-side-resnet50-inference) to skip the PC-side model conversion chapter.
:::

- Enter the ACUITY Toolkit Docker Container

  For ACUITY Toolkit Docker environment setup, please refer to [ACUITY Toolkit Environment Configuration](./cubie_acuity_env)

  Configure Environment Variables

      <Tabs>

  <TabItem value="A733">

          <NewCodeBlock tip="X86 Linux PC" type="PC">
          ```bash
          cd ai-sdk/models
          source env.sh v3 # NPU_VERSION
          cp ../scripts/* .
          ```
          </NewCodeBlock>

          </TabItem>

          <TabItem value="T527">

          <NewCodeBlock tip="X86 Linux PC" type="PC">
          ```bash
          cd ai-sdk/models
          source env.sh v2 # NPU_VERSION
          cp ../scripts/* .
          ```
          </NewCodeBlock>

          </TabItem>

      </Tabs>

  :::tip
  Specify NPU_VERSION: use `v3` for A733 and `v2` for T527. For reference, see [**NPU Version Comparison Table**](cubie_acuity_usage#npu-version-comparison-table)
  :::

- Download the ResNet50 ONNX Model

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  mkdir resnet50-sim && cd resnet50-sim
  wget https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx -O resnet50.onnx
  ```

  </NewCodeBlock>

- Fix Input Dimensions

  NPU inference only accepts fixed input dimensions. Here we use onnxsim to fix the input dimensions

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  pip3 install onnxsim onnxruntime
  onnxsim resnet50.onnx resnet50-sim.onnx --overwrite-input-shape 1,3,224,224
  ```

  </NewCodeBlock>

- Create Quantization Calibration Dataset

  Use an appropriate number of images to create a quantization calibration dataset. The image paths should be saved in `dataset.txt`

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  vim dataset.txt
  ```

  </NewCodeBlock>

  ```vim
  ./space_shuttle_224x224.jpg
  ```

  ![space_shuttle](/img/e/e54c/rs400_npu_3.webp)

- Make model input output file

  You can use [netron](https://netron.app/) to confirm the names of the model's input and output

   <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  vim inputs_outputs.txt
  ```

   </NewCodeBlock>

  ```vim
  --inputs data --input-size-list '3,224,224' --outputs 'resnetv24_dense0_fwd'
  ```

  {" "}

  <div style={{ textAlign: "center" }}>
    <img src="/img/cubie/a7a/resnet50_input.webp" />
    ResNet50 input/output names
  </div>

- Directory contains files

  ```bash
  .
  |-- dataset.txt
  |-- inputs_outputs.txt
  |-- resnet50-sim.onnx
  |-- resnet50.onnx
  `-- space_shuttle_224x224.jpg
  ```

- Parse the Model

  :::tip
  pegasus script is in ai-sdk/scripts, copy it to models directory
  :::

  Use `pegasus_import.sh` to parse the model into IR expression, will get `resnet50-sim.json` containing model structure and `resnet50-sim.data` containing model weights

   <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  ./pegasus_import.sh resnet50-sim/
  ```

   </NewCodeBlock>

- Modify resnet50-sim_inputmeta.yml file

  Since the training dataset is ImageNet, the normalization mean for the ImageNet training set is [0.485, 0.456, 0.406] and std is [0.229, 0.224, 0.225]. Denormalization calculation is required here. For normalization data, refer to [PyTorch documentation](https://docs.pytorch.org/vision/main/models/generated/torchvision.models.mobilenet_v2.html)

  ```bash
  # mean
  0.485 * 255 = 123.675
  0.456 * 255 = 116.28
  0.406 * 255 = 103.53
  ```

  ```bash
  # scale
  1 / (0.229 * 255) = 0.01712
  1 / (0.224 * 255) = 0.01751
  1 / (0.225 * 255) = 0.01743
  ```

  Modify the mean and scale values in `resnet50-sim_inputmeta.yml` according to the calculated mean and scale:

  ```vim
  mean:
  - 123.675
  - 116.28
  - 103.53
  scale:
  - 0.01712
  - 0.01751
  - 0.01743
  ```

  ```bash
  input_meta:
    databases:
    - path: dataset.txt
      type: TEXT
      ports:
      - lid: data_142
        category: image
        dtype: float32
        sparse: false
        tensor_name:
        layout: nchw
        shape:
        - 1
        - 3
        - 224
        - 224
        fitting: scale
        preprocess:
          reverse_channel: true
          mean:
          - 123.675
          - 116.28
          - 103.53
          scale:
          - 0.01712
          - 0.01751
          - 0.01743
          preproc_node_params:
            add_preproc_node: false
            preproc_type: IMAGE_RGB
            # preproc_dtype_converter:
              # quantizer: asymmetric_affine
              # qtype: uint8
              # scale: 1.0
              # zero_point: 0
            preproc_image_size:
            - 224
            - 224
            preproc_crop:
              enable_preproc_crop: false
              crop_rect:
              - 0
              - 0
              - 224
              - 224
            preproc_perm:
            - 0
            - 1
            - 2
            - 3
        redirect_to_output: false
  ```

- Quantize model

  Use `pegasus_quantize.sh` to quantize the model into uint8 type

   <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  ./pegasus_quantize.sh resnet50-sim/ uint8 10
  ```

   </NewCodeBlock>

- Compile model

  Use `./pegasus_export_ovx.sh` to compile the model into NBG model format

  <NewCodeBlock tip="X86 Linux PC" type="PC">

  ```bash
  ./pegasus_export_ovx.sh resnet50-sim/ uint8
  ```

  </NewCodeBlock>

  NBG model saved in `resnet50-sim/wksp/resnet50-sim_uint8_nbg_unify/network_binary.nb`

### Board-side ResNet50 Inference

Enter the resnet50 example code file directory path

<NewCodeBlock tip="Device" type="device">

```bash
cd ai-sdk/examples/resnet50
```

</NewCodeBlock>

### Compile Example

    <Tabs>
        <TabItem value="A733">

        <NewCodeBlock tip="Device" type="device">

        ```bash
        make AI_SDK_PLATFORM=a733
        make install AI_SDK_PLATFORM=a733 INSTALL_PREFIX=./
        ```

        </NewCodeBlock>

        </TabItem>

        <TabItem value="T527">

        <NewCodeBlock tip="Device" type="device">
        ```bash
        make AI_SDK_PLATFORM=t527
        make install AI_SDK_PLATFORM=t527 INSTALL_PREFIX=./
        ```
        </NewCodeBlock>

        </TabItem>

    </Tabs>

Parameter description:

`AI_SDK_PLATFORM`: Specify SoC, optional **`a733`**, **`t527`**

`INSTALL_PREFIX`: Specify installation path

### Run Example

Import environment variables

<Tabs>
    <TabItem value="A733">

    <NewCodeBlock tip="Device" type="device">

    ```bash
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/rock/ai-sdk/viplite-tina/lib/aarch64-none-linux-gnu/v2.0 # NPU_SW_VERSION
    ```

    </NewCodeBlock>

    </TabItem>

    <TabItem value="T527">

    <NewCodeBlock tip="Device" type="device">
    ```bash
    export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/home/rock/ai-sdk/viplite-tina/lib/aarch64-none-linux-gnu/v1.13 # NPU_SW_VERSION
    ```
    </NewCodeBlock>

    </TabItem>

</Tabs>

:::tip
Specify NPU_SW_VERSION: select `v2.0` for A733 and `v1.13` for T527. For NPU information, refer to [NPU Version Comparison Table](./cubie_acuity_usage#npu-version-comparison)
:::

Enter the example installation directory

<NewCodeBlock tip="Device" type="device">

```bash
cd $INSTALL_PREFIX/etc/npu/resnet50
# ./resnet50 nbg_model input_picture
./resnet50 model/resnet50.nb ./input_data/dog_224_224.jpg
```

</NewCodeBlock>

:::tip
The example will automatically install the resnet50.nb model provided by Radxa. Here you can manually specify the path to the user-converted NBG model.
:::

<div style={{ textAlign: "center" }}>
  <img src="/img/cubie/a7a/dog.webp" />
  resnet50 demo input image
</div>

```bash
(.venv) rock@radxa-cubie-a7a:~/ai-sdk/examples/resnet50/etc/npu/resnet50$ ./resnet50 ./model/network_binary.nb ./input_data/dog_224_224.jpg
./resnet50 nbg input
VIPLite driver software version 2.0.3.2-AW-2024-08-30
viplite init OK.
VIPLite driver version=0x00020003...
VIP cid=0x1000003b, device_count=1
* device[0] core_count=1
awnn_init total: 4.47 ms.
  vip_create_network ./model/network_binary.nb: 13.10 ms.
input 0 dim 224 224 3 1, data_format=2, name=input/output[0], elements=1833508979, scale=0.018657, zero_point=113
create input buffer 0: 150528
output 0 dim 1000 1, data_format=2, name=uid_1_out_0, elements=1000, scale=0.131327, zero_point=44
create output buffer 0: 1000
memory pool size=1606656 bytes
  load_param ./model/network_binary.nb: 0.19 ms.
  prepare network ./model/network_binary.nb: 2.58 ms.
  set network io ./model/network_binary.nb: 0.01 ms.
awnn_create total: 15.93 ms.
get jpeg success.
trans data success.
memcpy(0xffff96348000, 0xffff96162010, 150528)  load_input_data: 0.04 ms.
  vip_flush_buffer input: 0.01 ms.
awnn_set_input_buffers total: 0.06 ms.
awnn_set_input_buffers success.
  vip_run_network: 8.30 ms.
  vip_flush_buffer output: 0.01 ms.
    int8/uint8 1000 memcpy: 0.00 ms.
  tensor to fp: 0.02 ms.
awnn_run total: 8.35 ms.
awnn_run success.
class_postprocess.cpp run.
========== top5 ==========
class id: 231, prob: 13.395374, label: collie
class id: 230, prob: 12.082102, label: Shetland sheepdog, Shetland sheep dog, Shetland
class id: 169, prob: 10.900157, label: borzoi, Russian wolfhound
class id: 160, prob: 8.930249, label: Afghan hound, Afghan
class id: 224, prob: 7.222996, label: groenendael
class_postprocess success.
awnn_destroy total: 1.47 ms.
awnn_uninit total: 0.70 ms.
```
